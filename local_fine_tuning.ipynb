{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q transformers\n",
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM, AutoModelForQuestionAnswering\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert/distilgpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "max_length = 30\n",
    "prompt = \"There are two pencils in the box. Q: How many pencils? A:\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rajpurkar/squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unused columns\n",
    "dataset = dataset.remove_columns([\"id\", \"title\"])\n",
    "# Reduce dataset size\n",
    "dataset['train'] = dataset['train'].shuffle(seed=42).select(range(10000))\n",
    "dataset['validation'] = dataset['validation'].shuffle(seed=42).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_tokens = tokenizer.special_tokens_map\n",
    "\n",
    "# create tokenize function\n",
    "def tokenize_function(input_data):\n",
    "    predict = f'{input_data[\"context\"]} Q:{input_data[\"question\"]} A:{input_data[\"answers\"][\"text\"][0]}{special_tokens[\"bos_token\"]}'\n",
    "    inputs = tokenizer(\n",
    "        predict,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(tokenize_function, remove_columns=['context', 'question', 'answers'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reallocate_tokens(input_data, max_token_size=128):\n",
    "    combined_tokens = {\n",
    "        key: sum(values, [])\n",
    "        for key, values in input_data.items()\n",
    "    }\n",
    "\n",
    "    total_length = len(combined_tokens[list(input_data.keys())[0]])\n",
    "    total_length = (total_length // max_token_size) * max_token_size\n",
    "\n",
    "    token_blocks = {\n",
    "        key: [tokens[i: i + max_token_size] for i in range(0, total_length, max_token_size)]\n",
    "        for key, tokens in combined_tokens.items()\n",
    "    }\n",
    "\n",
    "    token_blocks['labels'] = token_blocks['input_ids'].copy()\n",
    "    return token_blocks\n",
    "\n",
    "\n",
    "dataset = dataset.map(reallocate_tokens,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(dataset['train'][0]['input_ids'])\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f'./{model_checkpoint}-ft',\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilgpt2-ft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2-ft\" # You can also load the model from checkpoints\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint)\n",
    "\n",
    "model.eval()\n",
    "max_length = 30\n",
    "prompt = \"There are two pencils in the box. Q: How many pencils? A:\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
